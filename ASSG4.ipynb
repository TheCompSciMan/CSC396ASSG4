{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1970001-b2d1-42d4-9201-b62245088227",
   "metadata": {},
   "source": [
    "# Setting up the GPU for use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae897dac-2f79-4b70-8fb2-e4e9fb645b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab7393a-a000-48ea-bc84-e2495041a9d7",
   "metadata": {},
   "source": [
    "# Question 1 #\n",
    "\n",
    "I am using the roberta model to encode the data. I start by reading in the text and adding it to an array. Then implement a data set class so I can use a data loader. I added a collate function so that we can pad per batch and it will handle the tokenization, badding, and truncation of that text. Then I go through every sentence in the text and tokenize it, calculate the contextualized and store them in a running dictionary that count how many embeddings we have summed per token. After the training we go through eack embedding and calculate the final embedding by averaging the contualized embeddings that were calculated. Then we save them to a file since this took about 2 hours to run. This code took me around 2 hours to write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5da4e0c8-7c23-49f5-9ad5-edd653345e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "with open(\"assignment4-dataset.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        text.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27aafb7e-9861-488b-a35b-efe22361b84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25e62ad-715d-499b-9858-465b9ce109c4",
   "metadata": {},
   "source": [
    "Note: I ran the code once and then saved the vectors. I accidentally started running it again but it stopped it. So it has run successfully but the last time I ran it I stopped it so that's why it looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "348988fd-7dde-438f-a30c-9cf8e61c0f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8886e1fc175a4aa0bfd2e25cfcc39be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch Progress:   0%|          | 0/69826 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     57\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     58\u001b[39m                 tokenEmbeddings[tok_id][\u001b[33m\"\u001b[39m\u001b[33msum\u001b[39m\u001b[33m\"\u001b[39m] += vec\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m                 tokenEmbeddings[tok_id][\u001b[33m\"\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m#print(tokenEmbeddings)\u001b[39;00m\n\u001b[32m     62\u001b[39m final_embeddings = {}\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.text[index]\n",
    "\n",
    "def collate_fn(batch_sentences):\n",
    "    return tokenizer(\n",
    "        batch_sentences,\n",
    "        padding=True,         # pad per batch to be more efficient\n",
    "        truncation=True,      \n",
    "        return_tensors='pt'   \n",
    "    )\n",
    "\n",
    "ds = SentenceDataset(text)\n",
    "dl = DataLoader(\n",
    "    ds,\n",
    "    batch_size=64,         \n",
    "    shuffle=False,         # order doesn't matter since we are reading all of them anyways\n",
    "    collate_fn=collate_fn  \n",
    ")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "tokenEmbeddings = {}\n",
    "\n",
    "\n",
    "for batch in tqdm(dl, desc=\"Batch Progress\"):\n",
    "    \n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        last_hidden = outputs.last_hidden_state  \n",
    "\n",
    "    input_ids = input_ids.cpu()\n",
    "    last_hidden = last_hidden.cpu()\n",
    "\n",
    "    # Accumulate embeddings\n",
    "    for sentence in range(input_ids.shape[0]):\n",
    "        for token in range(input_ids.shape[1]):\n",
    "            tok_id = int(input_ids[sentence][token])\n",
    "            if tok_id in tokenizer.all_special_ids:\n",
    "                continue  \n",
    "\n",
    "            vec = last_hidden[sentence][token]\n",
    "\n",
    "            if tok_id not in tokenEmbeddings:\n",
    "                tokenEmbeddings[tok_id] = {\"sum\": vec.clone(), \"count\": 1}\n",
    "            else:\n",
    "                tokenEmbeddings[tok_id][\"sum\"] += vec\n",
    "                tokenEmbeddings[tok_id][\"count\"] += 1\n",
    "\n",
    "#print(tokenEmbeddings)\n",
    "final_embeddings = {}\n",
    "for tok_id, data in tokenEmbeddings.items():\n",
    "    #print(\"tok:\", tok_id, \"data:\", data)\n",
    "    \n",
    "    final_embeddings[tok_id]= data[\"sum\"]/data[\"count\"]\n",
    "\n",
    "print(f\"Done! Computed static embeddings for {len(final_embeddings)} tokens.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "701e713f-8785-4fe0-95d1-d6f9abf72825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save embeddings to a file\n",
    "torch.save(final_embeddings, \"static_embeddingsTest.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3707fb-a075-45a9-91a1-bc771dae22a4",
   "metadata": {},
   "source": [
    "# Question 2 #\n",
    "\n",
    "We pull the saved vectors into memory and then read each word in the glove vocab and add them to an array. We then calculate the word embeddings by tokenizing the words and going through each token's embedding and then average them. After we get the word embeddings we make a word to id and id to word dictionaries so that we can use the most similar function that we saw in chapter 9. We have to manually normalize the vectors first since that code assumed the vectors were normalized. We then run most similar on the examples in the coding example. This code took me about 1.5-2 hours to write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64980944-6851-40a3-b4d6-5809f99fb01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49502\n"
     ]
    }
   ],
   "source": [
    "testVec = torch.load(\"static_embeddings.pt\")\n",
    "final_embeddings = testVec\n",
    "print(len(testVec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add52641-617c-48cc-9447-7c27725923bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open(\"glove.6B.300d-vocabulary.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        words.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b874337-8cf6-4c34-8211-589ef1d324cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4df66de1e743f48f1618170f72dcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing words:   0%|          | 0/400000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectors = []\n",
    "\n",
    "for word in tqdm(words, desc=\"Processing words\"):\n",
    "    ids = tokenizer(word)\n",
    "    vector = torch.zeros(768)\n",
    "    count = 0\n",
    "    for i in ids['input_ids']:\n",
    "        if i in final_embeddings:\n",
    "            count+=1\n",
    "            vector = vector + final_embeddings[i]\n",
    "    if count > 0:\n",
    "        vectors.append(vector / count)\n",
    "    else:\n",
    "        vectors.append(vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae58b28-1213-4ac8-9609-967ea571d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = {word: idx for idx, word in enumerate(words)}\n",
    "id_to_word = {idx: word for idx, word in enumerate(words)}\n",
    "vectors = np.array(vectors, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f27afa-8a4a-45dc-98d9-ae59fc17fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dot product should use normalized vectors so we need to manually normalize the vectors before using the code\n",
    "# compute norms\n",
    "norms = np.linalg.norm(vectors, axis=1)\n",
    "\n",
    "#some vectors could be zero so we replace their norms with 1 to not divide by 0\n",
    "norms[norms == 0] = 1.0\n",
    "\n",
    "# normalized matrix\n",
    "vectors = vectors / norms[:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87941491-953b-4e3a-a443-f8067402d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_words(word, vectors_normed, index_to_key, key_to_index, topn=10):\n",
    "    # get the id of the word\n",
    "    word_id = key_to_index[word]\n",
    "\n",
    "    # the embedding of the word\n",
    "    emb = vectors_normed[word_id]\n",
    "\n",
    "    #dot product\n",
    "    similarities = vectors_normed @ emb\n",
    "\n",
    "    # get best ids\n",
    "    ids_descending = np.argsort(similarities)[::-1]\n",
    "\n",
    "    # remove itself\n",
    "    ids_descending = ids_descending[ids_descending != word_id]\n",
    "\n",
    "    # return top-n words\n",
    "    top_ids = ids_descending[:topn]\n",
    "    return [(index_to_key[i], float(similarities[i])) for i in top_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1755ed96-94e6-4d34-9e51-c65da627ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cavalcanti', 0.9863354889365874),\n",
       " ('cercocarpus', 0.9861473498769773),\n",
       " ('cavalcante', 0.9860544568031278),\n",
       " ('candelas', 0.9858299012727044),\n",
       " ('carcasses', 0.9858295025702667),\n",
       " ('candel', 0.9858294191187436),\n",
       " ('cinecitta', 0.9857468884152574),\n",
       " ('crescenzio', 0.9856540147524828),\n",
       " ('cantus', 0.9855890225823372),\n",
       " ('carcosa', 0.9855605853317334)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_words('cactus',vectors,id_to_word,word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d494d3ac-4e83-4fe8-ab04-3303d0d4b3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cakebread', 0.9899608672106994),\n",
       " ('fruitcake', 0.9864247075655632),\n",
       " ('cakewalk', 0.9851424284707653),\n",
       " ('mooncake', 0.9828951083109528),\n",
       " ('cupcake', 0.9827581704871353),\n",
       " ('cakey', 0.9813415586594565),\n",
       " ('cakes', 0.9772956232114542),\n",
       " ('fruitcakes', 0.9770954168160269),\n",
       " ('beefcake', 0.9770783117066244),\n",
       " ('breadsticks', 0.9765364553065139)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_words('cake',vectors,id_to_word,word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d71cac50-a26e-42f2-9227-d4cad2d57714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ryang', 0.9999999999999999),\n",
       " ('ryanggang', 0.9949820219151513),\n",
       " ('mlanghenry', 0.9879471956721472),\n",
       " ('yungang', 0.9874037014721364),\n",
       " ('yarang', 0.986974789242882),\n",
       " ('yanchang', 0.9869184675772289),\n",
       " ('ryokan', 0.9867762689355988),\n",
       " ('ryokans', 0.986503959835086),\n",
       " ('zangara', 0.986425131677603),\n",
       " ('riang', 0.9863395297540736)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_words('angry',vectors,id_to_word,word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12741884-1d0e-42dd-9553-208a98856fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cleanly', 0.9868280206228188),\n",
       " ('closely', 0.986563200587705),\n",
       " ('quietly', 0.9863500507254755),\n",
       " ('solidly', 0.9860146388101536),\n",
       " ('coldly', 0.9855217456180718),\n",
       " ('wildly', 0.9852935517079322),\n",
       " ('smartly', 0.9851519293704964),\n",
       " ('safely', 0.9847266876867198),\n",
       " ('shortly', 0.9845230992649008),\n",
       " ('sweetly', 0.98441159181477)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_words('quickly',vectors,id_to_word,word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eeee9eb-f15b-455d-80b3-a11a833217d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inbetween', 0.9777306626590989),\n",
       " ('betweenness', 0.9733514115859017),\n",
       " ('inbetweeners', 0.964801160200541),\n",
       " ('in-between', 0.9600773334701196),\n",
       " ('go-between', 0.9579426240838547),\n",
       " ('below-average', 0.9422266431484709),\n",
       " ('below', 0.9411081084372184),\n",
       " ('near-future', 0.9401366101466174),\n",
       " ('nearshore', 0.9391151561161046),\n",
       " ('nearside', 0.9390195048005279)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_words('between',vectors,id_to_word,word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97b86ebe-e695-411e-adf7-217a65117b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bythe', 0.9832863368407013),\n",
       " ('andthe', 0.9827341979829303),\n",
       " ('thet', 0.9827293383206791),\n",
       " ('munthe', 0.9825837801469187),\n",
       " ('theming', 0.9817699051097706),\n",
       " ('theun', 0.9815891534772575),\n",
       " ('theory', 0.9812382748717261),\n",
       " ('grethe', 0.9811679464356251),\n",
       " ('thebe', 0.9810872220490177),\n",
       " ('thein', 0.9810202196263875)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_words('the',vectors,id_to_word,word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557e3d7-65ca-4ec8-b5f6-6d8446a2da90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
